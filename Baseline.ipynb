{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import generatevector\n",
    "from preprocess.parse import getRootSuffix\n",
    "from argparse import Namespace\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import CrossValidation\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd(vectors, dim=10):\n",
    "    svd = TruncatedSVD(n_components=dim, n_iter=10,random_state=2019)\n",
    "    svd_vectors = svd.fit_transform(vectors)\n",
    "    svd_cum_exp = svd.explained_variance_ratio_.sum()\n",
    "    print('Cumulated Explained Variance: {:.8f}'.format(svd_cum_exp))\n",
    "    return svd_vectors, svd_cum_exp\n",
    "\n",
    "def splitvector(vectors, labels, uni, testuni):\n",
    "    # split vector and label to train and test\n",
    "    idx = [i for i, x in enumerate(uni) if x == testuni]\n",
    "    test_vector = vectors[idx]\n",
    "    test_label = np.array(labels)[idx]\n",
    "    if isinstance(vectors, sp.csr_matrix):\n",
    "        train_vector = sp.csr_matrix(np.delete(vectors.toarray(), idx, 0))\n",
    "    else:\n",
    "        train_vector = sp.csr_matrix(np.delete(vectors, idx, 0))\n",
    "    train_label = np.delete(labels, idx)\n",
    "    return train_vector, train_label, test_vector, test_label\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.array(classes))\n",
    "    # Only use the labels that appear in the data\n",
    "    # classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def EvaluationModel(test_label, predict, classes):\n",
    "    print('Accuracy: {:.6f}'.format(metrics.accuracy_score(test_label, predict)))\n",
    "    print('Precision:{:.6f}'.format(precision_score(test_label, predict, average='weighted')))\n",
    "    print('Recall:{:.6f}'.format(recall_score(test_label, predict, average='weighted')))\n",
    "    print('F1_Score:{:.6f}'.format(f1_score(test_label, predict, average='weighted')))\n",
    "\n",
    "    np.set_printoptions(precision=2)\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plot_confusion_matrix(test_label, predict, classes=classes,\n",
    "                          title='Confusion matrix, without normalization')\n",
    "    # Plot normalized confusion matrix\n",
    "    plot_confusion_matrix(test_label, predict, classes=classes, normalize=True,\n",
    "                          title='Normalized confusion matrix')\n",
    "    plt.show()\n",
    "    \n",
    "def exec_time(start, end):\n",
    "    diff_time = end - start\n",
    "    m, s = divmod(diff_time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    s,m,h = int(round(s, 0)), int(round(m, 0)), int(round(h, 0))\n",
    "    return s, m, h\n",
    "\n",
    "def svmclassfier(train_vector, train_label, test_vector):\n",
    "    lin_clf = svm.LinearSVC()\n",
    "    lin_clf.fit(train_vector, train_label)\n",
    "    predict = lin_clf.predict(test_vector)\n",
    "    return predict\n",
    "\n",
    "\n",
    "def lrclassifier(train_vector, train_label, test_vector):\n",
    "    lr_clf = LogisticRegression()\n",
    "    lr_clf.fit(train_vector, train_label)\n",
    "    predict = lr_clf.predict(test_vector)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\software\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished model LogisticRegression on cornell validation set\n",
      "Execution Time: 00:00:17\n",
      "\n",
      "Finished model LogisticRegression on texas validation set\n",
      "Execution Time: 00:00:14\n",
      "\n",
      "Finished model LogisticRegression on washington validation set\n",
      "Execution Time: 00:00:14\n",
      "\n",
      "Finished model LogisticRegression on wisconsin validation set\n",
      "Execution Time: 00:00:13\n",
      "============================== Report overall cross validation performance ==============================\n",
      "Accuracy: 0.815503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:0.812223\n",
      "Recall:0.815503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score:0.811697\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     classes = [\"course\", \"department\", \"faculty\", \"other\", \"project\", \"staff\", \"student\"]\n",
    "#     args = Namespace(\n",
    "#         stop = False, \n",
    "#         stem = False, \n",
    "#         mime = False, \n",
    "#         digit = False, \n",
    "#         other = True\n",
    "#     )\n",
    "#     vectors, labels, uni, filename, features = generatevector.vectoriser('tfidf', args)\n",
    "#     lr_clf = LogisticRegression()\n",
    "#     label_t, label_p = CrossValidation.CrossValidation(lr_clf, vectors, labels, uni, classes, partial_p=False, cfsm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\n",
      "Finished model LogisticRegression on cornell validation set\n",
      "Execution Time: 00:00:15\n",
      "\n",
      "Finished model LogisticRegression on texas validation set\n",
      "Execution Time: 00:00:15\n",
      "\n",
      "Finished model LogisticRegression on washington validation set\n",
      "Execution Time: 00:00:13\n",
      "\n",
      "Finished model LogisticRegression on wisconsin validation set\n",
      "Execution Time: 00:00:13\n",
      "============================== Report overall cross validation performance ==============================\n",
      "Accuracy: 0.815503\n",
      "Precision:0.812223\n",
      "Recall:0.815503\n",
      "F1_Score:0.811697\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\n",
      "Finished model KNeighborsClassifier on cornell validation set\n",
      "Execution Time: 00:00:13\n",
      "\n",
      "Finished model KNeighborsClassifier on texas validation set\n",
      "Execution Time: 00:00:12\n",
      "\n",
      "Finished model KNeighborsClassifier on washington validation set\n",
      "Execution Time: 00:00:11\n",
      "\n",
      "Finished model KNeighborsClassifier on wisconsin validation set\n",
      "Execution Time: 00:00:11\n",
      "============================== Report overall cross validation performance ==============================\n",
      "Accuracy: 0.692859\n",
      "Precision:0.700990\n",
      "Recall:0.692859\n",
      "F1_Score:0.688441\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\n",
      "Finished model LinearSVC on cornell validation set\n",
      "Execution Time: 00:00:12\n",
      "\n",
      "Finished model LinearSVC on texas validation set\n",
      "Execution Time: 00:00:14\n",
      "\n",
      "Finished model LinearSVC on washington validation set\n",
      "Execution Time: 00:00:13\n",
      "\n",
      "Finished model LinearSVC on wisconsin validation set\n",
      "Execution Time: 00:00:14\n",
      "============================== Report overall cross validation performance ==============================\n",
      "Accuracy: 0.796124\n",
      "Precision:0.815080\n",
      "Recall:0.796124\n",
      "F1_Score:0.801509\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\n",
      "Finished model SVC on cornell validation set\n",
      "Execution Time: 00:01:11\n",
      "\n",
      "Finished model SVC on texas validation set\n",
      "Execution Time: 00:01:12\n",
      "\n",
      "Finished model SVC on washington validation set\n",
      "Execution Time: 00:01:04\n",
      "\n",
      "Finished model SVC on wisconsin validation set\n",
      "Execution Time: 00:01:03\n",
      "============================== Report overall cross validation performance ==============================\n",
      "Accuracy: 0.805415\n",
      "Precision:0.818486\n",
      "Recall:0.805415\n",
      "F1_Score:0.808320\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\n",
      "Finished model SVC on cornell validation set\n",
      "Execution Time: 00:01:16\n",
      "\n",
      "Finished model SVC on texas validation set\n",
      "Execution Time: 00:01:15\n",
      "\n",
      "Finished model SVC on washington validation set\n",
      "Execution Time: 00:01:14\n",
      "\n",
      "Finished model SVC on wisconsin validation set\n",
      "Execution Time: 00:01:11\n",
      "============================== Report overall cross validation performance ==============================\n",
      "Accuracy: 0.736660\n",
      "Precision:0.542669\n",
      "Recall:0.736660\n",
      "F1_Score:0.624957\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\n",
      "Finished model DecisionTreeClassifier on cornell validation set\n",
      "Execution Time: 00:00:15\n",
      "\n",
      "Finished model DecisionTreeClassifier on texas validation set\n",
      "Execution Time: 00:00:16\n",
      "\n",
      "Finished model DecisionTreeClassifier on washington validation set\n",
      "Execution Time: 00:00:14\n",
      "\n",
      "Finished model DecisionTreeClassifier on wisconsin validation set\n",
      "Execution Time: 00:00:15\n",
      "============================== Report overall cross validation performance ==============================\n",
      "Accuracy: 0.632333\n",
      "Precision:0.729628\n",
      "Recall:0.632333\n",
      "F1_Score:0.665433\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\n",
      "Finished model RandomForestClassifier on cornell validation set\n",
      "Execution Time: 00:00:16\n",
      "\n",
      "Finished model RandomForestClassifier on texas validation set\n",
      "Execution Time: 00:00:16\n",
      "\n",
      "Finished model RandomForestClassifier on washington validation set\n",
      "Execution Time: 00:00:17\n",
      "\n",
      "Finished model RandomForestClassifier on wisconsin validation set\n",
      "Execution Time: 00:00:13\n",
      "============================== Report overall cross validation performance ==============================\n",
      "Accuracy: 0.779666\n",
      "Precision:0.763402\n",
      "Recall:0.779666\n",
      "F1_Score:0.719536\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\n",
      "Finished model LGBMClassifier on cornell validation set\n",
      "Execution Time: 00:01:06\n",
      "\n",
      "Finished model LGBMClassifier on texas validation set\n",
      "Execution Time: 00:01:13\n",
      "\n",
      "Finished model LGBMClassifier on washington validation set\n",
      "Execution Time: 00:01:00\n",
      "\n",
      "Finished model LGBMClassifier on wisconsin validation set\n",
      "Execution Time: 00:01:05\n",
      "============================== Report overall cross validation performance ==============================\n",
      "Accuracy: 0.724715\n",
      "Precision:0.791713\n",
      "Recall:0.724715\n",
      "F1_Score:0.743075\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\n",
      "Finished model XGBClassifier on cornell validation set\n",
      "Execution Time: 00:04:10\n",
      "\n",
      "Finished model XGBClassifier on texas validation set\n",
      "Execution Time: 00:04:36\n",
      "\n",
      "Finished model XGBClassifier on washington validation set\n",
      "Execution Time: 00:04:03\n",
      "\n",
      "Finished model XGBClassifier on wisconsin validation set\n",
      "Execution Time: 00:03:33\n",
      "============================== Report overall cross validation performance ==============================\n",
      "Accuracy: 0.732944\n",
      "Precision:0.790708\n",
      "Recall:0.732944\n",
      "F1_Score:0.748199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "seed = 2019\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "names = [\"Logistic Regression\", \"Nearest Neighbors\", \"svm.LinearSVC\", \"Linear SVM\", \"RBF SVM\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"LightGBM\", \"XgBoost\"]\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(n_neighbors=7),\n",
    "    svm.LinearSVC(),\n",
    "    SVC(kernel=\"linear\", probability=False, random_state=seed),\n",
    "    SVC(kernel='rbf', probability=False, random_state=seed),\n",
    "    DecisionTreeClassifier(max_depth=10),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=50,random_state=seed),\n",
    "    lgbm.LGBMClassifier(),\n",
    "    xgb.XGBClassifier()]\n",
    "classes = [\"course\", \"department\", \"faculty\", \"other\", \"project\", \"staff\", \"student\"]\n",
    "args = Namespace(\n",
    "        stop = False, \n",
    "        stem = False, \n",
    "        mime = False, \n",
    "        digit = False, \n",
    "        other = True\n",
    "    )\n",
    "vectors, labels, uni, filename, features = generatevector.vectoriser('tfidf', args)\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print('='*100)\n",
    "    print('='*100)\n",
    "    print('='*100)\n",
    "    label_t, label_p = CrossValidation.CrossValidation(clf, vectors, labels, uni, classes, partial_p=False, cfsm=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
